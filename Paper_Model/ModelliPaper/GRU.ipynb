{"cells":[{"cell_type":"code","source":["import torch\n","print(torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zcIynbhndlnn","executionInfo":{"status":"ok","timestamp":1736764820903,"user_tz":-60,"elapsed":4591,"user":{"displayName":"Omar Coser","userId":"01334368924945290367"}},"outputId":"db8777e2-edf0-47f9-85d7-e9629ff48bd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.5.1+cu121\n"]}]},{"cell_type":"code","source":["pip install torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TUiYyoaq8muT","executionInfo":{"status":"ok","timestamp":1722233869508,"user_tz":-120,"elapsed":5049,"user":{"displayName":"Omar Coser","userId":"01334368924945290367"}},"outputId":"af7f5f86-d2af-4c56-f878-43adc7dcafa6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]}]},{"cell_type":"code","source":["pip install tsai"],"metadata":{"id":"uhn8-Bg4kh6o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tsai.all import *"],"metadata":{"id":"Mjai9Yj6lKJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(\"Script started\")\n","\n","import os\n","import numpy as np\n","import keras\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.metrics import r2_score\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","from tsai.tsai.models.TST import TST  # Import the TST model\n","from tsai.tsai.models.InceptionTime import InceptionTime  # Import the InceptionTime model\n","from tsai.tsai.models.RNN import GRU  # Import the GRU model from tsai\n","\n","\n","import argparse\n","#import argparse\n","\n","folder ='/fast/ocoser/DatiProva/DebuggEMG'\n","contents = os.listdir(folder)\n","print(contents)\n","\n","def load_data():\n","    Lista_Dati = []\n","    Lista_label = []\n","    Lista_Soggetto=[]\n","    file_list = os.listdir(\".\")\n","    for filename in contents:\n","        if \"Stair\" in filename or \"Treadmill\" in filename:\n","            file_path = os.path.join(folder, filename)\n","            f = open(file_path, \"r\")\n","            print(filename)\n","            for row in f.readlines():\n","                Row_S = row.strip().split(\",\")\n","                #print(Row_S)\n","                # print(len(Row_S))\n","                Lista_Dati.append(\n","                    (float(Row_S[1]), float(Row_S[2]), float(Row_S[3]), float(Row_S[4]), float(Row_S[5]),\n","                     float(Row_S[6]),\n","                     float(Row_S[7]), float(Row_S[8]), float(Row_S[9]), float(Row_S[10]),\n","                     float(Row_S[11])))\n","                Lista_label.append(Row_S[12])\n","                #print(row)\n","                if len(Row_S)>13:\n","                    Lista_Soggetto.append(Row_S[13])\n","                else:\n","                    Lista_Soggetto.append(\"none\")\n","                    #print(\"Sono qui\",Lista_Soggetto)\n","\n","    return Lista_Dati, Lista_label, Lista_Soggetto\n","\n","#load_data()\n","\n","\n","def Divido_per_soggetto(Lista_dati, Lista_label, Lista_Soggetto,soggetto):\n","    Training =[]\n","    Test = []\n","    Label_Training = []\n","    Label_Test = []\n","    for i in range(len(Lista_Soggetto)):\n","        if Lista_Soggetto[i] == soggetto:\n","            Test.append(Lista_dati[i])\n","            Label_Test.append(Lista_label[i])\n","        elif Lista_Soggetto[i] == \"none\":\n","            continue\n","        else:\n","            Training.append(Lista_dati[i])\n","            Label_Training.append(Lista_label[i])\n","\n","    return Training, Test, Label_Training, Label_Test\n","\n","\n","\n","\n","def finestre_temporali(Lista_dati, Lista_label):\n","    Grouped_List = []\n","    Lista_label_ridotta = []\n","    for i in range(0, len(Lista_dati), 500):\n","        group = Lista_dati[i:i + 500]\n","        group2 = Lista_label[i:i + 500]\n","        Grouped_List.append(group)\n","        Lista_label_ridotta.append(group2)\n","\n","    Lista_indici = []\n","    Lista_dati_Corretta = []\n","    for i in range(len(Lista_label_ridotta)):\n","        #print(Lista_label_ridotta[i])\n","        if len(set(Lista_label_ridotta[i])) < 2:\n","            Lista_indici.append(set(Lista_label_ridotta[i]))\n","            Lista_dati_Corretta.append(Grouped_List[i])\n","\n","    print(\"----\")\n","   # print(len(Lista_indici))\n","   # print(len(Lista_dati_Corretta))\n","    Lista_Indici_Finale = []\n","    #print(Lista_indici)\n","    #print(\"So qua\",Lista_indici)\n","    for el in Lista_indici:\n","        lista = list(el)\n","        for el2 in lista:\n","            Lista_Indici_Finale.append(el2)\n","   # print(\"Sono qua\",len(Lista_Indici_Finale), Lista_Indici_Finale)\n","    #print(\"Sono qua\",len(Lista_dati_Corretta), Lista_dati_Corretta)\n","\n","    return Lista_dati_Corretta, Lista_Indici_Finale\n","\n","\n","#print(\"ciao\")\n","#print(len(X2),len(X2_label))\n","#print(len(Y2),len(Y2_label))\n","\n","\n","## Senza Label ##\n","def Tolgo_Idle(X_1,y_1):\n","    X_new = []\n","    y_new = []\n","    for i in range(len(y_1)):\n","        if y_1[i] == \"idle\":\n","            continue\n","        else:\n","            X_new.append(X_1[i])\n","            y_new.append(y_1[i])\n","\n","    return X_new, y_new\n","\n","\n","\n","\n","#print(\"****\")\n","#print(len(X2_new), len(X2_label_new))\n","#print(len(Y2_new), len(Y2_label_new))\n","\n","def do_label_Corretta(Nuove):\n","    Y_new2 = []\n","    for el in Nuove:\n","        if el ==\"walk-stairascent\" or el ==\"stairascent\" or el ==\"stairascent-walk\":\n","            Y_new2.append(0)\n","        elif el == \"walk-stairdescent\" or el ==\"stairdescent\" or el ==\"stairdescent-walk\":\n","            Y_new2.append(1)\n","        elif el == \"walk-rampascent\" or el ==\"rampascent\" or el ==\"rampascent-walk\":\n","            Y_new2.append(2)\n","        elif el == \"walk-rampdescent\" or el ==\"rampdescent\" or el ==\"rampdescent-walk\":\n","            Y_new2.append(3)\n","        else:\n","            Y_new2.append(4)\n","\n","    return Y_new2\n","\n","#print(len(Train_label),Train_label)\n","#print(len(Test_label),Test_label)\n","def creo_numpy_array(Y_new2C, X_new):\n","    New_X = []\n","    New_y = []\n","    for i in range(len(X_new)):\n","        if len(X_new[i]) < 500:\n","            continue\n","        else:\n","            New_X.append(X_new[i])\n","            New_y.append(Y_new2C[i])\n","\n","    New_X = np.array(New_X)\n","    New_y = np.array(New_y)\n","    return New_X, New_y\n","\n","\n","\n","\n","def main(soggetto):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    # Load and preprocess data (assuming these functions are defined)\n","    Lista_dati, Lista_label, Lista_Soggetto = load_data()\n","    print(len(Lista_dati), len(Lista_label))\n","    X, Y, x_label, y_label = Divido_per_soggetto(Lista_dati, Lista_label, Lista_Soggetto, soggetto)\n","    X2, X2_label = finestre_temporali(X, x_label)\n","    Y2, Y2_label = finestre_temporali(Y, y_label)\n","    X2_new, X2_label_new = Tolgo_Idle(X2, X2_label)\n","    Y2_new, Y2_label_new = Tolgo_Idle(Y2, Y2_label)\n","    Train_label = do_label_Corretta(X2_label_new)\n","    Test_label = do_label_Corretta(Y2_label_new)\n","    Dati_X, label_x = creo_numpy_array(Train_label, X2_new)\n","    Dati_test_y, label_test_y = creo_numpy_array(Test_label, Y2_new)\n","    print(len(Dati_test_y))\n","\n","    # Convert numpy arrays to torch tensors.\n","    # IMPORTANT: TST expects input shape (batch, features, seq_len).\n","    # If Dati_X is of shape (num_samples, seq_len, features), we need to permute.\n","    Dati_X_torch = torch.tensor(Dati_X, dtype=torch.float32)  # shape: (N, seq_len, features)\n","    label_x_torch = torch.tensor(label_x, dtype=torch.float32).unsqueeze(1)  # shape: (N, 1)\n","\n","    Dati_test_y_torch = torch.tensor(Dati_test_y, dtype=torch.float32)\n","    label_test_y_torch = torch.tensor(label_test_y, dtype=torch.float32).unsqueeze(1)\n","\n","    # Permute from (N, seq_len, features) to (N, features, seq_len)\n","    Dati_X_torch = Dati_X_torch.permute(0, 2, 1)\n","    Dati_test_y_torch = Dati_test_y_torch.permute(0, 2, 1)\n","\n","    # Create DataLoaders for training and testing\n","    train_dataset = TensorDataset(Dati_X_torch, label_x_torch)\n","    test_dataset = TensorDataset(Dati_test_y_torch, label_test_y_torch)\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","    test_loader = DataLoader(test_dataset, batch_size=1, num_workers=2)\n","\n","    # Determine input dimensions from your data\n","    c_in = Dati_X_torch.shape[1]   # number of features\n","    seq_len = Dati_X_torch.shape[2]  # sequence length\n","    print(seq_len)\n","    # Initialize the TST model\n","    model = GRU(\n","    c_in=c_in,        # Number of input features\n","    c_out=1,          # Regression output (1D)\n","    hidden_size=128,  # Hidden layer size for GRU\n","    n_layers=1,       # Number of GRU layers\n","    bidirectional=False, # Use False for standard GRU\n","    fc_dropout=0.2    # Dropout to prevent overfitting\n","    ).to(device)\n","\n","    # Define loss function and optimizer\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # Training loop for 1 epoch\n","    print(\"Starting model training for 1 epoch...\")\n","    model.train()\n","    for epoch in range(1):  # Train for 1 epoch\n","        print(f\"Epoch {epoch+1} started...\")  # Debugging print\n","        for batch_idx, (batch_data, batch_labels) in enumerate(train_loader):\n","            print(f\"Processing batch {batch_idx+1}/{len(train_loader)}\")  # Debugging print\n","            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(batch_data)\n","            loss = criterion(outputs, batch_labels)\n","            loss.backward()\n","            optimizer.step()\n","        print(f\"Epoch {epoch+1} completed.\")\n","\n","\n","    # Evaluation\n","    model.eval()\n","    total_loss = 0.0\n","    preds = []\n","    truths = []\n","    with torch.no_grad():\n","        for batch_data, batch_labels in test_loader:\n","            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)  # Move batch to device\n","            outputs = model(batch_data)\n","            loss = criterion(outputs, batch_labels)\n","            total_loss += loss.item() * batch_data.size(0)\n","            preds.append(outputs)\n","            truths.append(batch_labels)\n","    total_loss /= len(test_dataset)\n","    preds = torch.cat(preds, dim=0)\n","    truths = torch.cat(truths, dim=0)\n","\n","    # Compute MAE, MSE and R2 Score\n","    mae = torch.mean(torch.abs(preds - truths)).item()\n","    mse = torch.mean((preds - truths)**2).item()\n","    ss_res = torch.sum((truths - preds) ** 2)\n","    ss_tot = torch.sum((truths - torch.mean(truths)) ** 2)\n","    r2 = 1 - ss_res / ss_tot\n","\n","    print(f'MSE: {mse:.8f}, MAE: {mae:.8f}, R2 Score: {r2:.8f}')\n","    print(f\"Subject processed: {soggetto}\")\n","#main(soggetto=\"AB06\")\n","\n","if __name__ == '__main__':\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"soggetto\", type=str, help=\"Subject identifier (e.g., AB06)\")\n","    args = parser.parse_args()\n","\n","    main(args.soggetto)  # Pass parsed argument to main\n"],"metadata":{"id":"Eat4xFoPXqjS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tsai.inference import load_learner\n","\n","mv_clf = load_learner(\"models/mv_clf.pkl\")\n","probas, target, preds = mv_clf.get_X_preds(X[splits[1]], y[splits[1]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"kfkxrR0HmBAf","executionInfo":{"status":"ok","timestamp":1736770607602,"user_tz":-60,"elapsed":5,"user":{"displayName":"Omar Coser","userId":"01334368924945290367"}},"outputId":"3fbc50bb-4abc-4561-b6cd-1e26109818d8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1B8NDtUApudZs7gwj_zGpiJW876zM58m3","timestamp":1700565923932}],"gpuType":"T4","authorship_tag":"ABX9TyNhhGjiSWlgG56GJV0LZwoq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}